{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM Image-based Feature Extraction\n",
    "Use RBM to perform feature extraction on an image-based dataset that you find or create. If you go this route, present the features you extract and explain why this is a useful feature extraction method in the context you’re operating in. DO NOT USE either the MNIST digit recognition database or the iris data set. They’ve been worked on in very public ways very very many times and the code is easily available. (However, that code could be a useful resource to refer to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying ships in satellite imagery\n",
    "This dataset is from kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "The dataset consists of image chips extracted from Planet satellite imagery collected over the San Franciso Bay area. It includes 2800 80x80 RGB images labeled with either a \"ship\" or \"no-ship\" classification. Image chips were derived from PlanetScope full-frame visual scene products, which are orthorectified to a 3 meter pixel size. The pixel value data for each 80x80 RGB image is stored as a list of 19200 integers within of the data list. The first 6400 entries contain the red channel values, the next 6400 the green, and the final 6400 the blue. The image is stored in row-major order, so that the first 80 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "The \"ship\" class includes 700 images. Images in this class are near-centered on the body of a single ship. Ships of different ship sizes, orientations, and atmospheric collection conditions are included. The \"no-ship\" class includes 2100 images. A third of these are a random sampling of different landcover features - water, vegetion, bare earth, buildings, etc. - that do not include any portion of an ship. The next third are \"partial ships\" that contain only a portion of an ship, but not enough to meet the full definition of the \"ship\" class. The last third are images that have previously been mislabeled by machine learning models, typically caused by bright pixels or string linear features. Example images from this class are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  labels  \\\n",
      "0  [82, 89, 91, 87, 89, 87, 86, 86, 86, 86, 84, 8...       1   \n",
      "1  [76, 75, 67, 62, 68, 72, 73, 73, 68, 69, 69, 6...       1   \n",
      "2  [125, 127, 129, 130, 126, 125, 129, 133, 132, ...       1   \n",
      "3  [102, 99, 113, 106, 96, 102, 105, 105, 103, 10...       1   \n",
      "4  [78, 76, 74, 78, 79, 79, 79, 82, 86, 85, 83, 8...       1   \n",
      "\n",
      "                                   locations             scene_ids  \n",
      "0    [-118.2254694333423, 33.73803725920789]  20180708_180909_0f47  \n",
      "1    [-122.33222866289329, 37.7491755586813]  20170705_180816_103e  \n",
      "2  [-118.14283073363218, 33.736016066914175]  20180712_211331_0f06  \n",
      "3   [-122.34784341495181, 37.76648707436548]  20170609_180756_103a  \n",
      "4   [-122.34852408322172, 37.75878462398653]  20170515_180653_1007  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('ships-in-satellite-imagery/shipsnet.json') as data_file:\n",
    "    dataset = json.load(data_file)\n",
    "df= pd.DataFrame(dataset)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 4000\n",
      "Number of NoShip Images: 3000\n",
      "Number of Ship Images: 1000\n",
      "Percentage of positive images: 25.00%\n",
      "Image shape (Width, Height, Channels): (19200,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(dataset['data']).astype('uint8')\n",
    "Y = np.array(dataset['labels']).astype('uint8')\n",
    "def describeData(a,b):\n",
    "    print('Total number of images: {}'.format(len(a)))\n",
    "    print('Number of NoShip Images: {}'.format(np.sum(b==0)))\n",
    "    print('Number of Ship Images: {}'.format(np.sum(b==1)))\n",
    "    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n",
    "    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\n",
    "describeData(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data         0\n",
       "labels       0\n",
       "locations    0\n",
       "scene_ids    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82  89  91 ...  86  88  89]\n",
      " [ 76  75  67 ...  54  57  58]\n",
      " [125 127 129 ... 111 109 115]\n",
      " ...\n",
      " [171 135 118 ...  95  95  85]\n",
      " [ 85  90  94 ...  96  95  89]\n",
      " [122 122 126 ...  51  46  69]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 19200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    " X, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train = X_train.reshape(1,-1)\n",
    "#Y_train = Y_train.reshape(-1)\n",
    "#X_train = (X_train - np.min(X, 0)) / (np.max(X_train, 0) + 0.0001)  # 0-1 scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models we will use\n",
    "from sklearn import linear_model\n",
    "logistic = linear_model.LogisticRegression(solver='lbfgs', max_iter=10000,\n",
    "                                           multi_class='multinomial')\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "rbm_features_classifier = Pipeline(\n",
    "    steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.n_components = 100\n",
    "logistic.C = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2419],\n",
       "       [   1,  781]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array(np.unique(Y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110 108 109 ...  99  95  92]\n",
      " [ 91  93  91 ...  91  90  90]\n",
      " [193 195 195 ... 186 186 194]\n",
      " ...\n",
      " [ 77  76  83 ...  75  76  76]\n",
      " [111 108 108 ...  95  97  99]\n",
      " [128 127 125 ... 116 114 121]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = 0.00, time = 14.01s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = 0.00, time = 13.86s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = 0.00, time = 14.35s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = 0.00, time = 13.48s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = 0.00, time = 12.97s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = 0.00, time = 13.53s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = 0.00, time = 15.27s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = 0.00, time = 14.75s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = 0.00, time = 13.70s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = 0.00, time = 13.75s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Training\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "# Training RBM-Logistic Pipeline\n",
    "rbm_features_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Training the Logistic regression classifier directly on the pixel\n",
    "raw_pixel_classifier = clone(logistic)\n",
    "raw_pixel_classifier.C = 100.\n",
    "raw_pixel_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using RBM features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       581\n",
      "           1       0.00      0.00      0.00       219\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       800\n",
      "   macro avg       0.36      0.50      0.42       800\n",
      "weighted avg       0.53      0.73      0.61       800\n",
      "\n",
      "\n",
      "Logistic regression using raw pixel features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       581\n",
      "           1       0.76      0.85      0.80       219\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       800\n",
      "   macro avg       0.85      0.87      0.86       800\n",
      "weighted avg       0.89      0.89      0.89       800\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "y_pred = rbm_features_classifier.predict(X_test)\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_test, y_pred)))\n",
    "\n",
    "y_pred = raw_pixel_classifier.predict(X_test)\n",
    "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

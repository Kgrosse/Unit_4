{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5 Challenge: Build your own NLP modelÂ¶\n",
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import requests             \n",
    "from bs4 import BeautifulSoup \n",
    "import csv                  \n",
    "import webbrowser\n",
    "import io\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\kgrosse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural\n",
    "print(list(inaugural.fileids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare two presidential speeches\n",
    "rsvlt = inaugural.raw('1905-Roosevelt.txt')\n",
    "taft = inaugural.raw('1909-Taft.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse with spacy language package\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "rsvlt_doc = nlp(rsvlt)\n",
    "taft_doc = nlp(taft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(My, fellow, citizens, ,, no, people, on, eart...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(To, us, as, a, people, it, has, been, granted...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(We, are, the, heirs, of, the, ages, ,, and, y...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(We, have, not, been, obliged, to, fight, for,...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Under, such, conditions, it, would, be, our, ...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1\n",
       "0  (My, fellow, citizens, ,, no, people, on, eart...  Roosevelt\n",
       "1  (To, us, as, a, people, it, has, been, granted...  Roosevelt\n",
       "2  (We, are, the, heirs, of, the, ages, ,, and, y...  Roosevelt\n",
       "3  (We, have, not, been, obliged, to, fight, for,...  Roosevelt\n",
       "4  (Under, such, conditions, it, would, be, our, ...  Roosevelt"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences and create data frame of sentences\n",
    "rsvlt_sents = [[sent, 'Roosevelt'] for sent in rsvlt_doc.sents]\n",
    "taft_sents = [[sent, 'Taft'] for sent in taft_doc.sents]\n",
    "\n",
    "# Combine\n",
    "sentences = pd.DataFrame(rsvlt_sents + taft_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My fellow citizens: Anyone who has taken the oath I have just taken must feel a heavy weight of responsibility. If not, he has no conception of the powers and duties of the office upon which he is about to enter, or he is lacking in a proper sense of the obligation which the oath imposes.\n",
      "\n",
      "The office of an inaugural address is to give a summary outline of the main policies of the new administration, so far as they can be anticipated. I have had the honor to be one of\n",
      "\n",
      "Taft speech length: 5888\n"
     ]
    }
   ],
   "source": [
    "print(taft_doc[:100])\n",
    "print('\\nTaft speech length:', len(taft_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My fellow citizens, no people on earth have more cause to be thankful than ours, and this is said reverently, in no spirit of boastfulness in our own strength, but with gratitude to the Giver of Good who has blessed us with the conditions which have enabled us to achieve so large a measure of well-being and of happiness. To us as a people it has been granted to lay the foundations of our national life in a new continent. We are the heirs of the ages, and yet we have\n",
      "\n",
      "Roosevelt speech length: 1094\n"
     ]
    }
   ],
   "source": [
    "print(rsvlt_doc[:100])\n",
    "print('\\nRoosevelt speech length:', len(rsvlt_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features using two different NLP methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(text):\n",
    "    #clean text\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "               if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    #get common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "#bags of words\n",
    "rsvlt_words = bow(rsvlt_doc)\n",
    "taft_words = bow(taft_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine bags\n",
    "common_words = set(rsvlt_words+taft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    }
   ],
   "source": [
    "print(type(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BOW datafame with common words and sentences\n",
    "def bow_features(sentences, common_words):\n",
    "    df=pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source']= sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    #process each row\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        #convert sentences to lemmas and filter\n",
    "        words = [token.lemma_\n",
    "                for token in sentence\n",
    "                if (\n",
    "                    not token.is_punct\n",
    "                    and not token.is_stop\n",
    "                    and token.lemma_ in common_words\n",
    "                )]\n",
    "        #populate the row with word counts\n",
    "        for word in words:\n",
    "            df.loc[i, word]+=1\n",
    "            \n",
    "            # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>interfere</th>\n",
       "      <th>continue</th>\n",
       "      <th>protection</th>\n",
       "      <th>expeditionary</th>\n",
       "      <th>prime</th>\n",
       "      <th>suppression</th>\n",
       "      <th>everyday</th>\n",
       "      <th>principle</th>\n",
       "      <th>scale</th>\n",
       "      <th>...</th>\n",
       "      <th>line</th>\n",
       "      <th>secure</th>\n",
       "      <th>banking</th>\n",
       "      <th>intense</th>\n",
       "      <th>financial</th>\n",
       "      <th>control</th>\n",
       "      <th>thankful</th>\n",
       "      <th>express</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(My, fellow, citizens, ,, no, people, on, eart...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(To, us, as, a, people, it, has, been, granted...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(We, are, the, heirs, of, the, ages, ,, and, y...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(We, have, not, been, obliged, to, fight, for,...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Under, such, conditions, it, would, be, our, ...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  free interfere continue protection expeditionary prime suppression everyday  \\\n",
       "0    0         0        0          0             0     0           0        0   \n",
       "1    0         0        0          0             0     0           0        0   \n",
       "2    0         0        0          0             0     0           0        0   \n",
       "3    0         0        0          0             0     0           0        0   \n",
       "4    1         0        0          0             0     0           0        0   \n",
       "\n",
       "  principle scale     ...     line secure banking intense financial control  \\\n",
       "0         0     0     ...        0      0       0       0         0       0   \n",
       "1         0     0     ...        0      0       0       0         0       0   \n",
       "2         0     0     ...        0      0       0       0         0       0   \n",
       "3         0     0     ...        0      0       0       0         0       0   \n",
       "4         0     0     ...        0      0       0       0         0       0   \n",
       "\n",
       "  thankful express                                      text_sentence  \\\n",
       "0        1       0  (My, fellow, citizens, ,, no, people, on, eart...   \n",
       "1        0       0  (To, us, as, a, people, it, has, been, granted...   \n",
       "2        0       0  (We, are, the, heirs, of, the, ages, ,, and, y...   \n",
       "3        0       0  (We, have, not, been, obliged, to, fight, for,...   \n",
       "4        0       0  (Under, such, conditions, it, would, be, our, ...   \n",
       "\n",
       "  text_source  \n",
       "0   Roosevelt  \n",
       "1   Roosevelt  \n",
       "2   Roosevelt  \n",
       "3   Roosevelt  \n",
       "4   Roosevelt  \n",
       "\n",
       "[5 rows x 686 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TF-IDF Features (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sentences\n",
    "rsvlt_sents = inaugural.sents('1905-Roosevelt.txt')\n",
    "taft_sents = inaugural.sents('1909-Taft.txt')\n",
    "\n",
    "#create lists of sentences and join them\n",
    "rsvlt_list = [\" \".join(sent) for sent in rsvlt_sents]\n",
    "taft_list = [\" \".join(sent)for sent in taft_sents]\n",
    "all_sents = rsvlt_list+taft_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(all_sents, test_size=0.4, random_state=0)\n",
    "#Vectorize\n",
    "vectorizor = TfidfVectorizer(max_df=0.5,\n",
    "                             min_df=2,\n",
    "                             stop_words='english',\n",
    "                             lowercase=True,\n",
    "                             use_idf=True,\n",
    "                             norm=u'l2',\n",
    "                             smooth_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 474\n"
     ]
    }
   ],
   "source": [
    "#apply the vectorizer\n",
    "taft_rsvlt_tfidf=vectorizor.fit_transform(all_sents)\n",
    "print('Number of features: %d'% taft_rsvlt_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshapes the vectorizer output into something people can read\n",
    "taft_rsvlt_tfidf_csr = taft_rsvlt_tfidf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(taft_rsvlt_tfidf, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create inputs\n",
    "\n",
    "#BOW\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'],1)\n",
    "Y_bow = bow['text_source']\n",
    "\n",
    "#Tfidf\n",
    "X_tfidf = taft_rsvlt_tfidf_csr\n",
    "Y_tfidf = ['Roosevelt']*len(rsvlt_list)+['Taft']*len(taft_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW LR Score:  0.8423558897243109\n",
      "Tfidf LR Score:  0.8285964912280702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Bow\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_bow,Y_bow)\n",
    "print('BOW LR Score: ', cross_val_score(lr_bow,X_bow,Y_bow, cv=10).mean())\n",
    "\n",
    "#Tfidf\n",
    "lr_tfidf = lr.fit(X_tfidf,Y_tfidf)\n",
    "print('Tfidf LR Score: ', cross_val_score(lr_tfidf,X_tfidf,Y_tfidf, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW RFC Score:  0.8328320802005014\n",
      "Tfidf RFC Score:  0.8499415204678362\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "#Bow\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_bow = rfc.fit(X_bow,Y_bow)\n",
    "print('BOW RFC Score: ', cross_val_score(rfc_bow,X_bow,Y_bow, cv=10).mean())\n",
    "\n",
    "#Tfidf\n",
    "rfc_tfidf = rfc.fit(X_tfidf,Y_tfidf)\n",
    "print('Tfidf RFC Score: ', cross_val_score(rfc_tfidf,X_tfidf,Y_tfidf, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW GBC Score:  0.8070175438596492\n",
      "Tfidf GBC Score:  0.8080701754385965\n"
     ]
    }
   ],
   "source": [
    "#Bow\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc_bow = gbc.fit(X_bow,Y_bow)\n",
    "print('BOW GBC Score: ', cross_val_score(gbc_bow,X_bow,Y_bow, cv=10).mean())\n",
    "\n",
    "#Tfidf\n",
    "gbc_tfidf = gbc.fit(X_tfidf,Y_tfidf)\n",
    "print('Tfidf GBC Score: ', cross_val_score(gbc_tfidf,X_tfidf,Y_tfidf, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a model and try to increase accuracy by 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase BoW size\n",
    "\n",
    "# Update function to include 1000 most common words and leave in punctuation\n",
    "def bow(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Get bags \n",
    "rsvlt_words2 = bow(rsvlt_doc)\n",
    "taft_words2 = bow(taft_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words2 = set(rsvlt_words2 + taft_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>interfere</th>\n",
       "      <th>continue</th>\n",
       "      <th>protection</th>\n",
       "      <th>expeditionary</th>\n",
       "      <th>prime</th>\n",
       "      <th>suppression</th>\n",
       "      <th>everyday</th>\n",
       "      <th>principle</th>\n",
       "      <th>scale</th>\n",
       "      <th>...</th>\n",
       "      <th>line</th>\n",
       "      <th>secure</th>\n",
       "      <th>banking</th>\n",
       "      <th>intense</th>\n",
       "      <th>financial</th>\n",
       "      <th>control</th>\n",
       "      <th>thankful</th>\n",
       "      <th>express</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(My, fellow, citizens, ,, no, people, on, eart...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(To, us, as, a, people, it, has, been, granted...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(We, are, the, heirs, of, the, ages, ,, and, y...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(We, have, not, been, obliged, to, fight, for,...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Under, such, conditions, it, would, be, our, ...</td>\n",
       "      <td>Roosevelt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  free interfere continue protection expeditionary prime suppression everyday  \\\n",
       "0    0         0        0          0             0     0           0        0   \n",
       "1    0         0        0          0             0     0           0        0   \n",
       "2    0         0        0          0             0     0           0        0   \n",
       "3    0         0        0          0             0     0           0        0   \n",
       "4    1         0        0          0             0     0           0        0   \n",
       "\n",
       "  principle scale     ...     line secure banking intense financial control  \\\n",
       "0         0     0     ...        0      0       0       0         0       0   \n",
       "1         0     0     ...        0      0       0       0         0       0   \n",
       "2         0     0     ...        0      0       0       0         0       0   \n",
       "3         0     0     ...        0      0       0       0         0       0   \n",
       "4         0     0     ...        0      0       0       0         0       0   \n",
       "\n",
       "  thankful express                                      text_sentence  \\\n",
       "0        1       0  (My, fellow, citizens, ,, no, people, on, eart...   \n",
       "1        0       0  (To, us, as, a, people, it, has, been, granted...   \n",
       "2        0       0  (We, are, the, heirs, of, the, ages, ,, and, y...   \n",
       "3        0       0  (We, have, not, been, obliged, to, fight, for,...   \n",
       "4        0       0  (Under, such, conditions, it, would, be, our, ...   \n",
       "\n",
       "  text_source  \n",
       "0   Roosevelt  \n",
       "1   Roosevelt  \n",
       "2   Roosevelt  \n",
       "3   Roosevelt  \n",
       "4   Roosevelt  \n",
       "\n",
       "[5 rows x 686 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow2 = bow_features(sentences, common_words)\n",
    "bow2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW 2 LR Scores:  0.8423558897243109\n"
     ]
    }
   ],
   "source": [
    "#Create new inputs\n",
    "X_bow2 = bow2.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow2 = bow2['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr_bow2 = lr.fit(X_bow2, Y_bow2)\n",
    "print('BOW 2 LR Scores: ', cross_val_score(lr_bow2, X_bow2, Y_bow2, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation and changing the number of common words did not change logistc regression score. Let's try it with another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new inputs\n",
    "X_bow2 = bow2.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow2 = bow2['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr_bow2 = lr.fit(X_bow2, Y_bow2)\n",
    "print('BOW 2 LR Scores: ', cross_val_score(lr_bow2, X_bow2, Y_bow2, cv=10).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
